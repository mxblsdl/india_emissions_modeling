---
title: "Task 6"
author: "Max Blasdel"
date: "October 30, 2018"
output: html_document
---
This document will be for completing task 6 from the India Emissions workflow.
Task 6 includes creating buffers around Urban areas at specified steps.
  Start with 1km as proof of concept on the subset data.
  *Make sure to use bilinear shapefile as that is more precise. I believe subset is made from non-bilinear dataset* 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The workflow document
```{r}
browseURL("https://docs.google.com/document/d/1fVqoTHjWP4AePL81nAPsvL5Mv2DwxabwEKEP8_dbA1g/edit")
```

Load required packages. Mapview and Mapedit are data visualization packages for exploring the data. There are some simple maps at the end of the script that use these packages. They are not essential for analysis.
```{r quietly=T}
library(sp)
library(sf)
library(data.table)
library(tidyverse)
library(mapview)
library(magrittr)
#require(mapedit)
```

# Test for how many polys from each distinction are present in file.

Read in the sp file of india and filter into urban and rural areas. *Subset used for testing purposes* 
I created a shapefile (.shp) of the bilinear dataset of india to work with. This could also be accomplished with the st_as_sf function from the sf package. 
```{r}
dat <- readRDS("geoData/fuelEndUses/merged_shp_w_fuelUseRasters_bilinear") %>% st_as_sf()

urb <- dat %>%
  filter(TRU=="Urban")
rur <- dat %>%
  filter(TRU=="Rural")

# Create table of values showing designation of TRU column
# Could be more elegant
df <- data.table("Urban" = nrow(urb),
           "Rural" = nrow(rur),
           "NA" = nrow(dat %>% filter(!TRU %in% c("Urban", "Rural"))))

df <- data.frame(t(df)) %>% 
  mutate(percentage = t.df./sum(t.df.))

row.names(df) <- (c("Urban", "Rural", "NA"))
colnames(df) <- c("Count","Percentage")

df
# Check to make sure number of NA rows matches
dat$TRU %>% is.na() %>% sum()

rm(dat)
```

# Read in RDS and subset into urban/rural

```{r}
# india <- readRDS("../output/spatial/poly_update_RDS_cleaned.rds")
india <- readRDS("../output/spatial/india_with_indicies.rds") %>% 
  st_as_sf() # final polygon file for analysis

# further filtering
#india <- india[1:10000,]

urb <- india %>% 
  filter(TRU == "Urban")
rur <- india %>% 
  filter(TRU == "Rural")

# I want to keep orig dataset for later merge
```

The data needs to be reprojectd so that meters buffer can be applied.

Projected to Asia South Albers Equal Area Conic EPSG: 102028
```{r}
urb <- st_transform(urb, crs = 102028)
rur <- st_transform(rur, crs = 102028)
```

# Create buffers of different radius. 

Units are in meters. The union function combines overlapping buffers from urban areas that are close together.
Large buffers added into mix
```{r}
#buffer_distances <- c(1000, 2000, 3000, 4000, 5000) %>% as.list()
buffer_distances <- c(1000, 2000, 3000, 4000, 5000, 10000, 15000, 20000)# %>% as.list()

#paste(buffer_distances[[1]]/1000, "km", sep="")

bufs <- lapply(buffer_distances, function(x) {
  st_buffer(urb$geometry, x) %>% 
    st_union()
})
```

Calculate area of the rural polygons
```{r}
rur <- rur %>%
  mutate(area = st_area(rur))
```

Now I need to look into how these intersect. I need to determine the area of the intersecting polygons from the buffer.
Attribute values are kept constant and need to be scaled based on the new area of the polygons.

*note* To Run on work computer
```{r}
start <- Sys.time()

intersections <- lapply(bufs, function(x) {
  st_intersection(rur, x)
})

Sys.time() - start
```

Calculate the area of the buffered polygon intersection.
```{r}
intersections_area <- lapply(intersections, function(x) {
  x %>% 
  mutate(new_area = st_area(.)) %>% #as.numeric()) %>% 
  mutate(proportional_area = new_area/area)
})

# Check outputs
intersections_area[[5]] %>% head()
```

All I care about is the proportional area column. What I want is this column with the buffer designation attached to the orig data set. This becomes five new columns for each scenario, whichcorresponds to the amount of polygon in the buffer/affected by the scenario.
```{r}
# ## Testing
# t <- intersections_area[[1]] %>% 
#   as.data.frame() %>% 
#   select(MY_ID, # to be replaced by MY_ID
#          proportional_area) %>% 
#   rename(scen1 = proportional_area)
```

Isolate the proportional area column and bind to original dataframe
```{r}
# create simple objects for merge
simp_inter <- lapply(intersections_area, function(x) {
  x %>% as.data.frame() %>% 
    select(MY_ID, proportional_area)
})

##TODO check the var length of simp_inter
## Rename variables to correspond to scenarios
for (i in 1:length(simp_inter)) {
  simp_inter[[i]] %<>% 
    rename(!!paste("buf_", buffer_distances[[1]]/1000, "km", sep = "") := proportional_area)
}

# add in the new columns to orig df. Works best in for loop
for (i in 1:length(simp_inter)) {
  india <- left_join(india, simp_inter[[i]], by="MY_ID")
}
```

# Change na values to 0
Make sure to double check indices
```{r}
newCols <- colnames(simp_inter)

india[,newCols][is.na(india[,newCols])] <- 0

india %>% as.data.frame() %>% head()
```

Read in poly with scnearios and merge new columns so all buffers are in one polygon
```{r}
## ?? did I mean to write RDS
read_rds("../output/spatial/poly_wScenarios_bigBuffs.rds")
```


Save the output for use in scenario modeling.
*needs to be run with full intersections, takes a while*
```{r}
#saveRDS(india, "../output/spatial/poly_wScenarios.rds")
saveRDS(india, "../output/spatial/poly_wScenarios_bigBuffs.rds")
```

Output the buffer objects for mapping
```{r}
# name each buffer
names(bufs) <- buffer_distances/1000

# write buffers to disk in loop with naming convention by km
for (i in 1:length(bufs)) {
  # project to WGS 84
  buf <- st_transform(bufs[[i]], 4326) 

  st_write(buf, paste0("../output/spatial/buffer_files/buf_", names(bufs[i]), ".shp"))
}
```

*Some potential workflow with the new calculated areas.*
So now I have intersection polygons of different lengths. The larger the buffer the more rural polygons that are included. Calculating new attributes is done by multiplying the proportional area by the attribute of interest. In this case that will be the eg_ck_r
```{r}
inter_one %>% 
  transmute(eg_ck_r_new = eg_ck_r*proportion_area,
            eg_ck_r = eg_ck_r,
            area = new_area,
            proportion_area = proportion_area) 
```

Writing the intersection outputs out for later use. These can be connected to the polygons by the C_CODE0 column. This might want to be done since the operations in this markdown can take a while to complete. 
```{r}
# I want to be able to save some of these outputs. I could use st_write for each inter_X
write.csv(inter_one, file = "output/inter1.csv")
write.csv(inter_two, file = "output/inter2.csv")
write.csv(inter_three, file = "output/inter3.csv")
write.csv(inter_four, file = "output/inter4.csv")
write.csv(inter_five, file = "output/inter5.csv")
```



Mapping the results some of the results. *Mapping Check a fairly heavy lift for the full dataset(crashes laptop)*
```{r}
cols<-sf.colors(n=5, categorical = T)

mapview(buf_five, col.regions=cols[1]) +
mapview(buf_four, col.regions=cols[2]) +
mapview(buf_three, col.regions=cols[3]) +
mapview(buf_two, col.regions=cols[4]) +
mapview(buf_one, col.regions=cols[5])
  mapview(rur)
```

Spot checking the buffered areas. Looking at the mapview map and selecting a polygon that falls partially in the buffer. Identified 'Tejapur' and the intersection calculates about 20% in the buffer. This visually looks about right, which is good. This is feature ID 459 around the middle buffer ring.
```{r}
inter_five %>% 
  filter(NAME == "Tejapur") %>% 
  select(area, new_area, proportion_area) %>%
  as.data.frame()
```



Playing with mapview
```{r}
require(mapedit)
m1<-mapView(inter, legend=T, burst=T)
m2<-mapview(rur)

sync(m1,m2)

mapview(rur, map=m1)

created_features<-mapview(inter) %>% editMap()

created_features$drawn$geometry$`0`[[1]]

```

